17/08/13 14:55:31 INFO SparkContext: Running Spark version 2.1.0
17/08/13 14:55:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/13 14:55:32 INFO SecurityManager: Changing view acls to: rstudio
17/08/13 14:55:32 INFO SecurityManager: Changing modify acls to: rstudio
17/08/13 14:55:32 INFO SecurityManager: Changing view acls groups to: 
17/08/13 14:55:32 INFO SecurityManager: Changing modify acls groups to: 
17/08/13 14:55:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rstudio); groups with view permissions: Set(); users  with modify permissions: Set(rstudio); groups with modify permissions: Set()
17/08/13 14:55:32 INFO Utils: Successfully started service 'sparkDriver' on port 43831.
17/08/13 14:55:32 INFO SparkEnv: Registering MapOutputTracker
17/08/13 14:55:32 INFO SparkEnv: Registering BlockManagerMaster
17/08/13 14:55:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/08/13 14:55:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/08/13 14:55:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-33f6ba3f-54bc-4a9c-89e6-92f9cd17a9f1
17/08/13 14:55:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/08/13 14:55:32 INFO SparkEnv: Registering OutputCommitCoordinator
17/08/13 14:55:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/08/13 14:55:33 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/08/13 14:55:33 INFO SparkContext: Added JAR file:/home/rstudio/R/x86_64-pc-linux-gnu-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:43831/jars/sparklyr-2.1-2.11.jar with timestamp 1502650533073
17/08/13 14:55:33 INFO Executor: Starting executor ID driver on host localhost
17/08/13 14:55:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35673.
17/08/13 14:55:33 INFO NettyBlockTransferService: Server created on 127.0.0.1:35673
17/08/13 14:55:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/08/13 14:55:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 35673, None)
17/08/13 14:55:33 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:35673 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 35673, None)
17/08/13 14:55:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 35673, None)
17/08/13 14:55:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 35673, None)
17/08/13 14:55:41 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/08/13 14:55:41 INFO SharedState: Warehouse path is 'file:/home/rstudio/R/Projetos/Indulto/SP/spark-warehouse'.
17/08/13 14:55:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/08/13 14:55:42 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/08/13 14:55:42 INFO ObjectStore: ObjectStore, initialize called
17/08/13 14:55:43 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/08/13 14:55:43 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/08/13 14:55:44 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/08/13 14:55:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/13 14:55:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/13 14:55:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/08/13 14:55:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/08/13 14:55:46 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/08/13 14:55:46 INFO ObjectStore: Initialized ObjectStore
17/08/13 14:55:46 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/08/13 14:55:46 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/08/13 14:55:46 INFO HiveMetaStore: Added admin role in metastore
17/08/13 14:55:46 INFO HiveMetaStore: Added public role in metastore
17/08/13 14:55:47 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/08/13 14:55:47 INFO HiveMetaStore: 0: get_all_databases
17/08/13 14:55:47 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_all_databases	
17/08/13 14:55:47 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/08/13 14:55:47 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/08/13 14:55:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/08/13 14:55:47 INFO SessionState: Created local directory: /tmp/75bdc510-b11e-4c08-b3c5-760ae6214eb7_resources
17/08/13 14:55:47 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio/75bdc510-b11e-4c08-b3c5-760ae6214eb7
17/08/13 14:55:47 INFO SessionState: Created local directory: /tmp/rstudio/75bdc510-b11e-4c08-b3c5-760ae6214eb7
17/08/13 14:55:47 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio/75bdc510-b11e-4c08-b3c5-760ae6214eb7/_tmp_space.db
17/08/13 14:55:47 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/rstudio/R/Projetos/Indulto/SP/spark-warehouse
17/08/13 14:55:47 INFO HiveMetaStore: 0: get_database: default
17/08/13 14:55:47 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 14:55:47 INFO HiveMetaStore: 0: get_database: global_temp
17/08/13 14:55:47 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/08/13 14:55:47 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/08/13 14:55:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 14:55:49 INFO HiveMetaStore: 0: get_database: default
17/08/13 14:55:49 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 14:55:49 INFO HiveMetaStore: 0: get_database: default
17/08/13 14:55:49 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 14:55:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 14:55:49 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 14:55:49 INFO CodeGenerator: Code generated in 286.305486 ms
17/08/13 14:55:49 INFO SparkContext: Starting job: collect at utils.scala:58
17/08/13 14:55:49 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/08/13 14:55:49 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/08/13 14:55:49 INFO DAGScheduler: Parents of final stage: List()
17/08/13 14:55:49 INFO DAGScheduler: Missing parents: List()
17/08/13 14:55:49 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/08/13 14:55:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/08/13 14:55:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/08/13 14:55:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:35673 (size: 4.6 KB, free: 366.3 MB)
17/08/13 14:55:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/08/13 14:55:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/08/13 14:55:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/08/13 14:55:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/08/13 14:55:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/08/13 14:55:50 INFO Executor: Fetching spark://127.0.0.1:43831/jars/sparklyr-2.1-2.11.jar with timestamp 1502650533073
17/08/13 14:55:50 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:43831 after 46 ms (0 ms spent in bootstraps)
17/08/13 14:55:50 INFO Utils: Fetching spark://127.0.0.1:43831/jars/sparklyr-2.1-2.11.jar to /tmp/spark-2f4ce049-6e85-4156-8edf-898b1280e793/userFiles-af33790c-7b03-4b94-9584-823dfd9e0d01/fetchFileTemp617143030784478303.tmp
17/08/13 14:55:50 INFO Executor: Adding file:/tmp/spark-2f4ce049-6e85-4156-8edf-898b1280e793/userFiles-af33790c-7b03-4b94-9584-823dfd9e0d01/sparklyr-2.1-2.11.jar to class loader
17/08/13 14:55:50 INFO CodeGenerator: Code generated in 13.009675 ms
17/08/13 14:55:50 INFO CodeGenerator: Code generated in 11.574711 ms
17/08/13 14:55:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/08/13 14:55:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 264 ms on localhost (executor driver) (1/1)
17/08/13 14:55:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/08/13 14:55:50 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0,296 s
17/08/13 14:55:50 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0,463435 s
17/08/13 14:55:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 14:55:50 INFO SparkSqlParser: Parsing command: b
17/08/13 14:55:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 14:55:50 INFO SparkSqlParser: Parsing command: CACHE TABLE `b`
17/08/13 14:55:50 INFO SparkSqlParser: Parsing command: `b`
17/08/13 14:55:50 INFO FileSourceStrategy: Pruning directories with: 
17/08/13 14:55:50 INFO FileSourceStrategy: Post-Scan Filters: 
17/08/13 14:55:50 INFO FileSourceStrategy: Output Data Schema: struct<processo: string, total: int>
17/08/13 14:55:50 INFO FileSourceStrategy: Pushed Filters: 
17/08/13 14:55:50 INFO CodeGenerator: Code generated in 9.038611 ms
17/08/13 14:55:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 290.9 KB, free 366.0 MB)
17/08/13 14:55:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 366.0 MB)
17/08/13 14:55:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:35673 (size: 23.8 KB, free: 366.3 MB)
17/08/13 14:55:50 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/08/13 14:55:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/08/13 14:55:50 INFO CodeGenerator: Code generated in 13.842296 ms
17/08/13 14:55:50 INFO CodeGenerator: Code generated in 10.580693 ms
17/08/13 14:55:50 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/08/13 14:55:51 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
17/08/13 14:55:51 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/08/13 14:55:51 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/08/13 14:55:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/08/13 14:55:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/08/13 14:55:51 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.9 KB, free 366.0 MB)
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 9.5 KB, free 366.0 MB)
17/08/13 14:55:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:35673 (size: 9.5 KB, free: 366.3 MB)
17/08/13 14:55:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/08/13 14:55:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/08/13 14:55:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6646 bytes)
17/08/13 14:55:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/08/13 14:55:51 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp3q5dOj/spark_serialize_e17d840a0162566d8acc0e4b39d6441616da1790fd8aa17ecc799642ff55f243.csv, range: 0-26741, partition values: [empty row]
17/08/13 14:55:51 INFO CodeGenerator: Code generated in 7.834006 ms
17/08/13 14:55:51 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 26.1 KB, free 365.9 MB)
17/08/13 14:55:51 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:35673 (size: 26.1 KB, free: 366.2 MB)
17/08/13 14:55:51 INFO CodeGenerator: Code generated in 4.673791 ms
17/08/13 14:55:51 INFO CodeGenerator: Code generated in 19.115182 ms
17/08/13 14:55:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2997 bytes result sent to driver
17/08/13 14:55:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 296 ms on localhost (executor driver) (1/1)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/08/13 14:55:51 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0,297 s
17/08/13 14:55:51 INFO DAGScheduler: looking for newly runnable stages
17/08/13 14:55:51 INFO DAGScheduler: running: Set()
17/08/13 14:55:51 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/08/13 14:55:51 INFO DAGScheduler: failed: Set()
17/08/13 14:55:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/08/13 14:55:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 366.2 MB)
17/08/13 14:55:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/08/13 14:55:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/08/13 14:55:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/08/13 14:55:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/08/13 14:55:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 14:55:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/08/13 14:55:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2129 bytes result sent to driver
17/08/13 14:55:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 41 ms on localhost (executor driver) (1/1)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/08/13 14:55:51 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0,032 s
17/08/13 14:55:51 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0,394299 s
17/08/13 14:55:51 INFO CodeGenerator: Code generated in 8.198457 ms
17/08/13 14:55:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 14:55:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `b`
17/08/13 14:55:51 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 14:55:51 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:196)
17/08/13 14:55:51 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/08/13 14:55:51 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/08/13 14:55:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/08/13 14:55:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/08/13 14:55:51 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:196), which has no missing parents
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 17.9 KB, free 365.9 MB)
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.5 KB, free 365.9 MB)
17/08/13 14:55:51 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:35673 (size: 9.5 KB, free: 366.2 MB)
17/08/13 14:55:51 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/08/13 14:55:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:196)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/08/13 14:55:51 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6638 bytes)
17/08/13 14:55:51 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/08/13 14:55:51 INFO BlockManager: Found block rdd_9_0 locally
17/08/13 14:55:51 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2275 bytes result sent to driver
17/08/13 14:55:51 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0,015 s
17/08/13 14:55:51 INFO DAGScheduler: looking for newly runnable stages
17/08/13 14:55:51 INFO DAGScheduler: running: Set()
17/08/13 14:55:51 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/08/13 14:55:51 INFO DAGScheduler: failed: Set()
17/08/13 14:55:51 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 365.9 MB)
17/08/13 14:55:51 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.9 MB)
17/08/13 14:55:51 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 14 ms on localhost (executor driver) (1/1)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/08/13 14:55:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 366.2 MB)
17/08/13 14:55:51 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/08/13 14:55:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/08/13 14:55:51 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/08/13 14:55:51 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/08/13 14:55:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 14:55:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 14:55:51 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/08/13 14:55:51 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 9 ms on localhost (executor driver) (1/1)
17/08/13 14:55:51 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/08/13 14:55:51 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0,010 s
17/08/13 14:55:51 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0,043441 s
17/08/13 14:55:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 14:55:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `b` AS `zzz1`
WHERE (0 = 1)
17/08/13 14:55:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 14:55:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 14:55:51 INFO HiveMetaStore: 0: get_database: default
17/08/13 14:55:51 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 14:55:51 INFO HiveMetaStore: 0: get_database: default
17/08/13 14:55:51 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 14:55:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 14:55:51 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 14:55:52 INFO CodeGenerator: Code generated in 10.028297 ms
17/08/13 14:55:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 14:55:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 14:55:52 INFO HiveMetaStore: 0: get_database: default
17/08/13 14:55:52 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 14:55:52 INFO HiveMetaStore: 0: get_database: default
17/08/13 14:55:52 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 14:55:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 14:55:52 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:00:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:00:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:00:33 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:00:33 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:00:33 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:00:33 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:00:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:00:33 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:00:33 INFO SparkContext: Starting job: collect at utils.scala:58
17/08/13 15:00:33 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/08/13 15:00:33 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/08/13 15:00:33 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:00:33 INFO DAGScheduler: Missing parents: List()
17/08/13 15:00:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/08/13 15:00:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 365.9 MB)
17/08/13 15:00:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 365.9 MB)
17/08/13 15:00:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:35673 (size: 4.6 KB, free: 366.2 MB)
17/08/13 15:00:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/08/13 15:00:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/08/13 15:00:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/08/13 15:00:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6350 bytes)
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 54
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 55
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 56
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 57
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 58
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 59
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 60
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 61
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 62
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 63
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 64
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 65
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 66
17/08/13 15:00:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/08/13 15:00:33 INFO ContextCleaner: Cleaned shuffle 0
17/08/13 15:00:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1235 bytes result sent to driver
17/08/13 15:00:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 26 ms on localhost (executor driver) (1/1)
17/08/13 15:00:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/08/13 15:00:33 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0,027 s
17/08/13 15:00:33 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0,068714 s
17/08/13 15:00:33 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:35673 in memory (size: 9.5 KB, free: 366.2 MB)
17/08/13 15:00:33 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 366.2 MB)
17/08/13 15:00:33 INFO ContextCleaner: Cleaned accumulator 163
17/08/13 15:00:33 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:35673 in memory (size: 9.5 KB, free: 366.2 MB)
17/08/13 15:00:33 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 366.2 MB)
17/08/13 15:00:33 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:00:34 INFO SparkSqlParser: Parsing command: df
17/08/13 15:00:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:00:34 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/08/13 15:00:34 INFO SparkSqlParser: Parsing command: `df`
17/08/13 15:00:34 INFO FileSourceStrategy: Pruning directories with: 
17/08/13 15:00:34 INFO FileSourceStrategy: Post-Scan Filters: 
17/08/13 15:00:34 INFO FileSourceStrategy: Output Data Schema: struct<customerID: string, gender: string, SeniorCitizen: int, Partner: string, Dependents: string ... 19 more fields>
17/08/13 15:00:34 INFO FileSourceStrategy: Pushed Filters: 
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 290.9 KB, free 365.7 MB)
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.8 KB, free 365.6 MB)
17/08/13 15:00:34 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:35673 (size: 23.8 KB, free: 366.2 MB)
17/08/13 15:00:34 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/08/13 15:00:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/08/13 15:00:34 INFO ContextCleaner: Cleaned accumulator 274
17/08/13 15:00:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:35673 in memory (size: 4.6 KB, free: 366.2 MB)
17/08/13 15:00:34 INFO ContextCleaner: Cleaned accumulator 273
17/08/13 15:00:34 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:35673 in memory (size: 4.6 KB, free: 366.2 MB)
17/08/13 15:00:34 INFO ContextCleaner: Cleaned accumulator 1
17/08/13 15:00:34 INFO ContextCleaner: Cleaned accumulator 0
17/08/13 15:00:34 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/08/13 15:00:34 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/08/13 15:00:34 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/08/13 15:00:34 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/08/13 15:00:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/08/13 15:00:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/08/13 15:00:34 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 30.2 KB, free 365.6 MB)
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 12.9 KB, free 365.6 MB)
17/08/13 15:00:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:35673 (size: 12.9 KB, free: 366.2 MB)
17/08/13 15:00:34 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/08/13 15:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/08/13 15:00:34 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6646 bytes)
17/08/13 15:00:34 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/08/13 15:00:34 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp3q5dOj/spark_serialize_95bfc57ff51ac0754294f9419883af792b62986da2f34db8730936391656c0c3.csv, range: 0-1209950, partition values: [empty row]
17/08/13 15:00:34 INFO CodeGenerator: Code generated in 18.695737 ms
17/08/13 15:00:34 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 443.6 KB, free 365.2 MB)
17/08/13 15:00:34 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:35673 (size: 443.6 KB, free: 365.8 MB)
17/08/13 15:00:34 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2910 bytes result sent to driver
17/08/13 15:00:34 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 449 ms on localhost (executor driver) (1/1)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/08/13 15:00:34 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 0,450 s
17/08/13 15:00:34 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:00:34 INFO DAGScheduler: running: Set()
17/08/13 15:00:34 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/08/13 15:00:34 INFO DAGScheduler: failed: Set()
17/08/13 15:00:34 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 365.2 MB)
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.2 MB)
17/08/13 15:00:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.8 MB)
17/08/13 15:00:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/08/13 15:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/08/13 15:00:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/08/13 15:00:34 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/08/13 15:00:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:00:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:00:34 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2129 bytes result sent to driver
17/08/13 15:00:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/08/13 15:00:34 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0,008 s
17/08/13 15:00:34 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 0,478316 s
17/08/13 15:00:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:00:34 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/08/13 15:00:34 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:00:34 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/08/13 15:00:34 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:00:34 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/08/13 15:00:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/08/13 15:00:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/08/13 15:00:34 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 30.2 KB, free 365.1 MB)
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.0 KB, free 365.1 MB)
17/08/13 15:00:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:35673 (size: 13.0 KB, free: 365.8 MB)
17/08/13 15:00:34 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/08/13 15:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/08/13 15:00:34 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6639 bytes)
17/08/13 15:00:34 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/08/13 15:00:34 INFO BlockManager: Found block rdd_34_0 locally
17/08/13 15:00:34 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2188 bytes result sent to driver
17/08/13 15:00:34 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/08/13 15:00:34 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0,009 s
17/08/13 15:00:34 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:00:34 INFO DAGScheduler: running: Set()
17/08/13 15:00:34 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/08/13 15:00:34 INFO DAGScheduler: failed: Set()
17/08/13 15:00:34 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 365.1 MB)
17/08/13 15:00:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.1 MB)
17/08/13 15:00:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.8 MB)
17/08/13 15:00:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/08/13 15:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/08/13 15:00:34 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/08/13 15:00:34 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
17/08/13 15:00:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:00:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:00:34 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2042 bytes result sent to driver
17/08/13 15:00:34 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 23 ms on localhost (executor driver) (1/1)
17/08/13 15:00:34 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/08/13 15:00:34 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0,023 s
17/08/13 15:00:34 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0,049580 s
17/08/13 15:00:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:00:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz2`
WHERE (0 = 1)
17/08/13 15:00:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:00:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:00:35 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:00:35 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:00:35 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:00:35 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:00:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:00:35 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:00:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:00:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:00:35 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:00:35 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:00:35 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:00:35 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:00:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:00:35 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:03:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:03:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
LIMIT 25
17/08/13 15:03:47 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:03:47 INFO DAGScheduler: Got job 6 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:03:47 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:196)
17/08/13 15:03:47 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:03:47 INFO DAGScheduler: Missing parents: List()
17/08/13 15:03:47 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[51] at collect at utils.scala:196), which has no missing parents
17/08/13 15:03:47 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 26.3 KB, free 365.1 MB)
17/08/13 15:03:47 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 11.6 KB, free 365.1 MB)
17/08/13 15:03:47 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:35673 (size: 11.6 KB, free: 365.8 MB)
17/08/13 15:03:47 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/08/13 15:03:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[51] at collect at utils.scala:196)
17/08/13 15:03:47 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/08/13 15:03:47 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6565 bytes)
17/08/13 15:03:47 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/08/13 15:03:47 INFO BlockManager: Found block rdd_34_0 locally
17/08/13 15:03:47 INFO CodeGenerator: Code generated in 29.47389 ms
17/08/13 15:03:47 WARN Executor: 1 block locks were not released by TID = 10:
[rdd_34_0]
17/08/13 15:03:47 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 4680 bytes result sent to driver
17/08/13 15:03:47 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 78 ms on localhost (executor driver) (1/1)
17/08/13 15:03:47 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/08/13 15:03:47 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:196) finished in 0,078 s
17/08/13 15:03:47 INFO DAGScheduler: Job 6 finished: collect at utils.scala:196, took 0,089649 s
17/08/13 15:03:47 INFO CodeGenerator: Code generated in 23.820793 ms
17/08/13 15:05:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:05:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/08/13 15:05:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/08/13 15:05:17 INFO DAGScheduler: Registering RDD 54 (count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/08/13 15:05:17 INFO DAGScheduler: Final stage: ResultStage 12 (count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/08/13 15:05:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/08/13 15:05:17 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 30.2 KB, free 365.1 MB)
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.9 KB, free 365.0 MB)
17/08/13 15:05:17 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:35673 (size: 12.9 KB, free: 365.7 MB)
17/08/13 15:05:17 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/08/13 15:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/08/13 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6640 bytes)
17/08/13 15:05:17 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/08/13 15:05:17 INFO BlockManager: Found block rdd_34_0 locally
17/08/13 15:05:17 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2188 bytes result sent to driver
17/08/13 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/08/13 15:05:17 INFO DAGScheduler: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0,009 s
17/08/13 15:05:17 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:05:17 INFO DAGScheduler: running: Set()
17/08/13 15:05:17 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/08/13 15:05:17 INFO DAGScheduler: failed: Set()
17/08/13 15:05:17 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 365.0 MB)
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.0 MB)
17/08/13 15:05:17 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.7 MB)
17/08/13 15:05:17 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/08/13 15:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/08/13 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/08/13 15:05:17 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/08/13 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:05:17 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1955 bytes result sent to driver
17/08/13 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 9 ms on localhost (executor driver) (1/1)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/08/13 15:05:17 INFO DAGScheduler: ResultStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0,010 s
17/08/13 15:05:17 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0,035742 s
17/08/13 15:05:17 INFO CodeGenerator: Code generated in 16.472487 ms
17/08/13 15:05:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/08/13 15:05:17 INFO DAGScheduler: Registering RDD 60 (count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/08/13 15:05:17 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/08/13 15:05:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/08/13 15:05:17 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[60] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 37.6 KB, free 365.0 MB)
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 15.0 KB, free 365.0 MB)
17/08/13 15:05:17 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:35673 (size: 15.0 KB, free: 365.7 MB)
17/08/13 15:05:17 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/08/13 15:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[60] at count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/08/13 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6640 bytes)
17/08/13 15:05:17 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/08/13 15:05:17 INFO BlockManager: Found block rdd_34_0 locally
17/08/13 15:05:17 INFO CodeGenerator: Code generated in 18.197689 ms
17/08/13 15:05:17 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2250 bytes result sent to driver
17/08/13 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 77 ms on localhost (executor driver) (1/1)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/08/13 15:05:17 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0,072 s
17/08/13 15:05:17 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:05:17 INFO DAGScheduler: running: Set()
17/08/13 15:05:17 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/08/13 15:05:17 INFO DAGScheduler: failed: Set()
17/08/13 15:05:17 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[63] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 7.0 KB, free 365.0 MB)
17/08/13 15:05:17 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 3.7 KB, free 365.0 MB)
17/08/13 15:05:17 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.7 MB)
17/08/13 15:05:17 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/08/13 15:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[63] at count at NativeMethodAccessorImpl.java:0)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/08/13 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/08/13 15:05:17 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
17/08/13 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:05:17 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2042 bytes result sent to driver
17/08/13 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
17/08/13 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/08/13 15:05:17 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0,007 s
17/08/13 15:05:17 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0,103838 s
17/08/13 15:05:17 INFO SparkSqlParser: Parsing command: sparklyr_tmp_4abc19502fc2
17/08/13 15:05:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:05:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4abc19502fc2` AS `zzz3`
WHERE (0 = 1)
17/08/13 15:05:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:05:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4abc19502fc2`
17/08/13 15:05:17 INFO CodeGenerator: Code generated in 15.498097 ms
17/08/13 15:07:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:07:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_4abc19502fc2`
LIMIT 25
17/08/13 15:07:52 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:07:52 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:07:52 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:196)
17/08/13 15:07:52 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:07:52 INFO DAGScheduler: Missing parents: List()
17/08/13 15:07:52 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[69] at collect at utils.scala:196), which has no missing parents
17/08/13 15:07:52 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 47.4 KB, free 364.9 MB)
17/08/13 15:07:52 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 16.9 KB, free 364.9 MB)
17/08/13 15:07:52 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:35673 (size: 16.9 KB, free: 365.7 MB)
17/08/13 15:07:52 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/08/13 15:07:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[69] at collect at utils.scala:196)
17/08/13 15:07:52 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/08/13 15:07:52 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6565 bytes)
17/08/13 15:07:52 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
17/08/13 15:07:52 INFO BlockManager: Found block rdd_34_0 locally
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 327
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.7 MB)
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:35673 in memory (size: 11.6 KB, free: 365.7 MB)
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 595
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 596
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 597
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 598
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 599
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 600
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 601
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 602
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 603
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 604
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 605
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 606
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 607
17/08/13 15:07:52 INFO ContextCleaner: Cleaned shuffle 4
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:35673 in memory (size: 12.9 KB, free: 365.7 MB)
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.7 MB)
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 704
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 705
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 706
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 707
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 708
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 709
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 710
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 711
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 712
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 713
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 714
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 715
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 716
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 717
17/08/13 15:07:52 INFO ContextCleaner: Cleaned shuffle 5
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:35673 in memory (size: 15.0 KB, free: 365.7 MB)
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.7 MB)
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 328
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 329
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 330
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 331
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 332
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 333
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 334
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 335
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 336
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 337
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 338
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 339
17/08/13 15:07:52 INFO ContextCleaner: Cleaned shuffle 2
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:35673 in memory (size: 12.9 KB, free: 365.8 MB)
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.8 MB)
17/08/13 15:07:52 INFO ContextCleaner: Cleaned accumulator 436
17/08/13 15:07:52 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:35673 in memory (size: 13.0 KB, free: 365.8 MB)
17/08/13 15:07:52 INFO MemoryStore: Block rdd_67_0 stored as values in memory (estimated size 442.9 KB, free 364.7 MB)
17/08/13 15:07:52 INFO BlockManagerInfo: Added rdd_67_0 in memory on 127.0.0.1:35673 (size: 442.9 KB, free: 365.3 MB)
17/08/13 15:07:52 WARN Executor: 1 block locks were not released by TID = 15:
[rdd_67_0]
17/08/13 15:07:52 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 5732 bytes result sent to driver
17/08/13 15:07:52 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 180 ms on localhost (executor driver) (1/1)
17/08/13 15:07:52 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/08/13 15:07:52 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:196) finished in 0,179 s
17/08/13 15:07:52 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0,191977 s
17/08/13 15:11:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:11:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:11:26 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:11:26 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:11:26 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:11:26 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:11:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:11:26 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:11:26 INFO SparkContext: Starting job: collect at utils.scala:58
17/08/13 15:11:26 INFO DAGScheduler: Got job 10 (collect at utils.scala:58) with 1 output partitions
17/08/13 15:11:26 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:58)
17/08/13 15:11:26 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:11:26 INFO DAGScheduler: Missing parents: List()
17/08/13 15:11:26 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[75] at map at utils.scala:55), which has no missing parents
17/08/13 15:11:26 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.7 KB, free 364.7 MB)
17/08/13 15:11:26 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.6 KB, free 364.7 MB)
17/08/13 15:11:26 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:35673 (size: 4.6 KB, free: 365.3 MB)
17/08/13 15:11:26 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/08/13 15:11:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[75] at map at utils.scala:55)
17/08/13 15:11:26 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/08/13 15:11:26 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 6472 bytes)
17/08/13 15:11:26 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
17/08/13 15:11:26 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1268 bytes result sent to driver
17/08/13 15:11:26 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 8 ms on localhost (executor driver) (1/1)
17/08/13 15:11:26 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/08/13 15:11:26 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:58) finished in 0,006 s
17/08/13 15:11:26 INFO DAGScheduler: Job 10 finished: collect at utils.scala:58, took 0,014991 s
17/08/13 15:11:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:13:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:13:30 INFO SparkSqlParser: Parsing command: UNCACHE TABLE `df`
17/08/13 15:13:30 INFO SparkSqlParser: Parsing command: `df`
17/08/13 15:13:30 INFO MapPartitionsRDD: Removing RDD 34 from persistence list
17/08/13 15:13:30 INFO BlockManager: Removing RDD 34
17/08/13 15:15:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:15:42 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:42 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:42 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:42 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:15:42 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:15:42 INFO SparkContext: Starting job: collect at utils.scala:58
17/08/13 15:15:42 INFO DAGScheduler: Got job 11 (collect at utils.scala:58) with 1 output partitions
17/08/13 15:15:42 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:58)
17/08/13 15:15:42 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:15:42 INFO DAGScheduler: Missing parents: List()
17/08/13 15:15:42 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[82] at map at utils.scala:55), which has no missing parents
17/08/13 15:15:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.7 KB, free 365.1 MB)
17/08/13 15:15:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.6 KB, free 365.1 MB)
17/08/13 15:15:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:35673 (size: 4.6 KB, free: 365.8 MB)
17/08/13 15:15:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/08/13 15:15:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[82] at map at utils.scala:55)
17/08/13 15:15:42 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/08/13 15:15:42 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6472 bytes)
17/08/13 15:15:42 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
17/08/13 15:15:42 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1268 bytes result sent to driver
17/08/13 15:15:42 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 6 ms on localhost (executor driver) (1/1)
17/08/13 15:15:42 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/08/13 15:15:42 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:58) finished in 0,005 s
17/08/13 15:15:42 INFO DAGScheduler: Job 11 finished: collect at utils.scala:58, took 0,012551 s
17/08/13 15:15:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:15:57 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:57 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:57 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:57 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:15:57 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:15:57 INFO SparkContext: Starting job: collect at utils.scala:58
17/08/13 15:15:57 INFO DAGScheduler: Got job 12 (collect at utils.scala:58) with 1 output partitions
17/08/13 15:15:57 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:58)
17/08/13 15:15:57 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:15:57 INFO DAGScheduler: Missing parents: List()
17/08/13 15:15:57 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[88] at map at utils.scala:55), which has no missing parents
17/08/13 15:15:57 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 8.7 KB, free 365.1 MB)
17/08/13 15:15:57 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 4.6 KB, free 365.1 MB)
17/08/13 15:15:57 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:35673 (size: 4.6 KB, free: 365.8 MB)
17/08/13 15:15:57 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/08/13 15:15:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[88] at map at utils.scala:55)
17/08/13 15:15:57 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/08/13 15:15:57 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 6472 bytes)
17/08/13 15:15:57 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
17/08/13 15:15:57 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1268 bytes result sent to driver
17/08/13 15:15:57 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 6 ms on localhost (executor driver) (1/1)
17/08/13 15:15:57 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/08/13 15:15:57 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:58) finished in 0,007 s
17/08/13 15:15:57 INFO DAGScheduler: Job 12 finished: collect at utils.scala:58, took 0,011867 s
17/08/13 15:15:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:57 INFO SparkSqlParser: Parsing command: df
17/08/13 15:15:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:57 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/08/13 15:15:57 INFO SparkSqlParser: Parsing command: `df`
17/08/13 15:15:57 INFO FileSourceStrategy: Pruning directories with: 
17/08/13 15:15:57 INFO FileSourceStrategy: Post-Scan Filters: 
17/08/13 15:15:57 INFO FileSourceStrategy: Output Data Schema: struct<customerID: string, gender: string, SeniorCitizen: int, Partner: string, Dependents: string ... 19 more fields>
17/08/13 15:15:57 INFO FileSourceStrategy: Pushed Filters: 
17/08/13 15:15:57 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 290.9 KB, free 364.8 MB)
17/08/13 15:15:57 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.8 KB, free 364.8 MB)
17/08/13 15:15:57 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:35673 (size: 23.8 KB, free: 365.7 MB)
17/08/13 15:15:57 INFO SparkContext: Created broadcast 21 from sql at <unknown>:0
17/08/13 15:15:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/08/13 15:15:58 INFO SparkContext: Starting job: sql at <unknown>:0
17/08/13 15:15:58 INFO DAGScheduler: Registering RDD 95 (sql at <unknown>:0)
17/08/13 15:15:58 INFO DAGScheduler: Got job 13 (sql at <unknown>:0) with 1 output partitions
17/08/13 15:15:58 INFO DAGScheduler: Final stage: ResultStage 20 (sql at <unknown>:0)
17/08/13 15:15:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
17/08/13 15:15:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
17/08/13 15:15:58 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[95] at sql at <unknown>:0), which has no missing parents
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 30.2 KB, free 364.8 MB)
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.8 MB)
17/08/13 15:15:58 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:35673 (size: 13.0 KB, free: 365.7 MB)
17/08/13 15:15:58 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/08/13 15:15:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[95] at sql at <unknown>:0)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/08/13 15:15:58 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6648 bytes)
17/08/13 15:15:58 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
17/08/13 15:15:58 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp3q5dOj/spark_serialize_95bfc57ff51ac0754294f9419883af792b62986da2f34db8730936391656c0c3.csv, range: 0-1209950, partition values: [empty row]
17/08/13 15:15:58 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:35673 in memory (size: 4.6 KB, free: 365.7 MB)
17/08/13 15:15:58 INFO ContextCleaner: Cleaned accumulator 1022
17/08/13 15:15:58 INFO ContextCleaner: Cleaned accumulator 868
17/08/13 15:15:58 INFO ContextCleaner: Cleaned accumulator 869
17/08/13 15:15:58 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:35673 in memory (size: 4.6 KB, free: 365.7 MB)
17/08/13 15:15:58 INFO ContextCleaner: Cleaned accumulator 918
17/08/13 15:15:58 INFO ContextCleaner: Cleaned accumulator 919
17/08/13 15:15:58 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:35673 in memory (size: 4.6 KB, free: 365.7 MB)
17/08/13 15:15:58 INFO ContextCleaner: Cleaned accumulator 968
17/08/13 15:15:58 INFO ContextCleaner: Cleaned accumulator 969
17/08/13 15:15:58 INFO MemoryStore: Block rdd_92_0 stored as values in memory (estimated size 443.6 KB, free 364.4 MB)
17/08/13 15:15:58 INFO BlockManagerInfo: Added rdd_92_0 in memory on 127.0.0.1:35673 (size: 443.6 KB, free: 365.3 MB)
17/08/13 15:15:58 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2983 bytes result sent to driver
17/08/13 15:15:58 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 176 ms on localhost (executor driver) (1/1)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/08/13 15:15:58 INFO DAGScheduler: ShuffleMapStage 19 (sql at <unknown>:0) finished in 0,176 s
17/08/13 15:15:58 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:15:58 INFO DAGScheduler: running: Set()
17/08/13 15:15:58 INFO DAGScheduler: waiting: Set(ResultStage 20)
17/08/13 15:15:58 INFO DAGScheduler: failed: Set()
17/08/13 15:15:58 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[98] at sql at <unknown>:0), which has no missing parents
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.0 KB, free 364.4 MB)
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.4 MB)
17/08/13 15:15:58 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.3 MB)
17/08/13 15:15:58 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/08/13 15:15:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[98] at sql at <unknown>:0)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/08/13 15:15:58 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/08/13 15:15:58 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
17/08/13 15:15:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:15:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:15:58 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2042 bytes result sent to driver
17/08/13 15:15:58 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 4 ms on localhost (executor driver) (1/1)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/08/13 15:15:58 INFO DAGScheduler: ResultStage 20 (sql at <unknown>:0) finished in 0,004 s
17/08/13 15:15:58 INFO DAGScheduler: Job 13 finished: sql at <unknown>:0, took 0,194843 s
17/08/13 15:15:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:58 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/08/13 15:15:58 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:15:58 INFO DAGScheduler: Registering RDD 102 (collect at utils.scala:196)
17/08/13 15:15:58 INFO DAGScheduler: Got job 14 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:15:58 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:196)
17/08/13 15:15:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
17/08/13 15:15:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
17/08/13 15:15:58 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[102] at collect at utils.scala:196), which has no missing parents
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 30.2 KB, free 364.3 MB)
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 12.9 KB, free 364.3 MB)
17/08/13 15:15:58 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:35673 (size: 12.9 KB, free: 365.3 MB)
17/08/13 15:15:58 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/08/13 15:15:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[102] at collect at utils.scala:196)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/08/13 15:15:58 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6640 bytes)
17/08/13 15:15:58 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
17/08/13 15:15:58 INFO BlockManager: Found block rdd_92_0 locally
17/08/13 15:15:58 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 2188 bytes result sent to driver
17/08/13 15:15:58 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 8 ms on localhost (executor driver) (1/1)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/08/13 15:15:58 INFO DAGScheduler: ShuffleMapStage 21 (collect at utils.scala:196) finished in 0,008 s
17/08/13 15:15:58 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:15:58 INFO DAGScheduler: running: Set()
17/08/13 15:15:58 INFO DAGScheduler: waiting: Set(ResultStage 22)
17/08/13 15:15:58 INFO DAGScheduler: failed: Set()
17/08/13 15:15:58 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[105] at collect at utils.scala:196), which has no missing parents
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.0 KB, free 364.3 MB)
17/08/13 15:15:58 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.3 MB)
17/08/13 15:15:58 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.3 MB)
17/08/13 15:15:58 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/08/13 15:15:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[105] at collect at utils.scala:196)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/08/13 15:15:58 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/08/13 15:15:58 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
17/08/13 15:15:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:15:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:15:58 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 2042 bytes result sent to driver
17/08/13 15:15:58 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
17/08/13 15:15:58 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/08/13 15:15:58 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:196) finished in 0,005 s
17/08/13 15:15:58 INFO DAGScheduler: Job 14 finished: collect at utils.scala:196, took 0,024744 s
17/08/13 15:15:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz4`
WHERE (0 = 1)
17/08/13 15:15:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:15:58 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:58 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:15:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:15:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:15:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/08/13 15:15:58 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:58 INFO HiveMetaStore: 0: get_database: default
17/08/13 15:15:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
17/08/13 15:15:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/08/13 15:15:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/08/13 15:16:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:16:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
LIMIT 25
17/08/13 15:16:14 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:16:14 INFO DAGScheduler: Got job 15 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:16:14 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:196)
17/08/13 15:16:14 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:16:14 INFO DAGScheduler: Missing parents: List()
17/08/13 15:16:14 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[109] at collect at utils.scala:196), which has no missing parents
17/08/13 15:16:14 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 26.3 KB, free 364.3 MB)
17/08/13 15:16:14 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 11.5 KB, free 364.3 MB)
17/08/13 15:16:14 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:35673 (size: 11.5 KB, free: 365.3 MB)
17/08/13 15:16:14 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/08/13 15:16:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[109] at collect at utils.scala:196)
17/08/13 15:16:14 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/08/13 15:16:14 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6565 bytes)
17/08/13 15:16:14 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
17/08/13 15:16:14 INFO BlockManager: Found block rdd_92_0 locally
17/08/13 15:16:14 WARN Executor: 1 block locks were not released by TID = 23:
[rdd_92_0]
17/08/13 15:16:14 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 4680 bytes result sent to driver
17/08/13 15:16:14 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 10 ms on localhost (executor driver) (1/1)
17/08/13 15:16:14 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/08/13 15:16:14 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:196) finished in 0,011 s
17/08/13 15:16:14 INFO DAGScheduler: Job 15 finished: collect at utils.scala:196, took 0,016097 s
17/08/13 15:19:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:19:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/08/13 15:19:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:19:38 INFO DAGScheduler: Registering RDD 112 (collect at utils.scala:196)
17/08/13 15:19:38 INFO DAGScheduler: Got job 16 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:19:38 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:196)
17/08/13 15:19:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
17/08/13 15:19:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
17/08/13 15:19:38 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[112] at collect at utils.scala:196), which has no missing parents
17/08/13 15:19:38 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 30.3 KB, free 364.3 MB)
17/08/13 15:19:38 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 13.1 KB, free 364.2 MB)
17/08/13 15:19:38 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:35673 (size: 13.1 KB, free: 365.3 MB)
17/08/13 15:19:38 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
17/08/13 15:19:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[112] at collect at utils.scala:196)
17/08/13 15:19:38 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/08/13 15:19:38 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6640 bytes)
17/08/13 15:19:38 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
17/08/13 15:19:38 INFO BlockManager: Found block rdd_92_0 locally
17/08/13 15:19:38 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2188 bytes result sent to driver
17/08/13 15:19:38 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 9 ms on localhost (executor driver) (1/1)
17/08/13 15:19:38 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/08/13 15:19:38 INFO DAGScheduler: ShuffleMapStage 24 (collect at utils.scala:196) finished in 0,009 s
17/08/13 15:19:38 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:19:38 INFO DAGScheduler: running: Set()
17/08/13 15:19:38 INFO DAGScheduler: waiting: Set(ResultStage 25)
17/08/13 15:19:38 INFO DAGScheduler: failed: Set()
17/08/13 15:19:38 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[115] at collect at utils.scala:196), which has no missing parents
17/08/13 15:19:38 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 364.2 MB)
17/08/13 15:19:38 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.2 MB)
17/08/13 15:19:38 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.3 MB)
17/08/13 15:19:38 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/08/13 15:19:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[115] at collect at utils.scala:196)
17/08/13 15:19:38 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/08/13 15:19:38 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/08/13 15:19:38 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
17/08/13 15:19:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:19:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:19:38 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2042 bytes result sent to driver
17/08/13 15:19:38 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 5 ms on localhost (executor driver) (1/1)
17/08/13 15:19:38 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/08/13 15:19:38 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:196) finished in 0,005 s
17/08/13 15:19:38 INFO DAGScheduler: Job 16 finished: collect at utils.scala:196, took 0,024105 s
17/08/13 15:19:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:19:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
LIMIT 25
17/08/13 15:19:43 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:19:43 INFO DAGScheduler: Got job 17 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:19:43 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:196)
17/08/13 15:19:43 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:19:43 INFO DAGScheduler: Missing parents: List()
17/08/13 15:19:43 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[117] at collect at utils.scala:196), which has no missing parents
17/08/13 15:19:43 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 26.3 KB, free 364.2 MB)
17/08/13 15:19:43 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.5 KB, free 364.2 MB)
17/08/13 15:19:43 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:35673 (size: 11.5 KB, free: 365.3 MB)
17/08/13 15:19:43 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/08/13 15:19:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[117] at collect at utils.scala:196)
17/08/13 15:19:43 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/08/13 15:19:43 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6565 bytes)
17/08/13 15:19:43 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
17/08/13 15:19:43 INFO BlockManager: Found block rdd_92_0 locally
17/08/13 15:19:43 WARN Executor: 1 block locks were not released by TID = 26:
[rdd_92_0]
17/08/13 15:19:43 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 4680 bytes result sent to driver
17/08/13 15:19:43 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 6 ms on localhost (executor driver) (1/1)
17/08/13 15:19:43 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/08/13 15:19:43 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:196) finished in 0,005 s
17/08/13 15:19:43 INFO DAGScheduler: Job 17 finished: collect at utils.scala:196, took 0,014014 s
17/08/13 15:24:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:24:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/08/13 15:24:08 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:24:08 INFO DAGScheduler: Registering RDD 120 (collect at utils.scala:196)
17/08/13 15:24:08 INFO DAGScheduler: Got job 18 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:24:08 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:196)
17/08/13 15:24:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
17/08/13 15:24:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
17/08/13 15:24:08 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[120] at collect at utils.scala:196), which has no missing parents
17/08/13 15:24:08 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 30.3 KB, free 364.2 MB)
17/08/13 15:24:08 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 13.0 KB, free 364.1 MB)
17/08/13 15:24:08 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:35673 (size: 13.0 KB, free: 365.2 MB)
17/08/13 15:24:08 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
17/08/13 15:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[120] at collect at utils.scala:196)
17/08/13 15:24:08 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/08/13 15:24:08 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6640 bytes)
17/08/13 15:24:08 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
17/08/13 15:24:08 INFO BlockManager: Found block rdd_92_0 locally
17/08/13 15:24:08 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 2188 bytes result sent to driver
17/08/13 15:24:08 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 10 ms on localhost (executor driver) (1/1)
17/08/13 15:24:08 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/08/13 15:24:08 INFO DAGScheduler: ShuffleMapStage 27 (collect at utils.scala:196) finished in 0,012 s
17/08/13 15:24:08 INFO DAGScheduler: looking for newly runnable stages
17/08/13 15:24:08 INFO DAGScheduler: running: Set()
17/08/13 15:24:08 INFO DAGScheduler: waiting: Set(ResultStage 28)
17/08/13 15:24:08 INFO DAGScheduler: failed: Set()
17/08/13 15:24:08 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[123] at collect at utils.scala:196), which has no missing parents
17/08/13 15:24:08 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.0 KB, free 364.1 MB)
17/08/13 15:24:08 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.7 KB, free 364.1 MB)
17/08/13 15:24:08 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:35673 (size: 3.7 KB, free: 365.2 MB)
17/08/13 15:24:08 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/08/13 15:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[123] at collect at utils.scala:196)
17/08/13 15:24:08 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
17/08/13 15:24:08 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/08/13 15:24:08 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
17/08/13 15:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/08/13 15:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/08/13 15:24:08 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 2042 bytes result sent to driver
17/08/13 15:24:08 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 4 ms on localhost (executor driver) (1/1)
17/08/13 15:24:08 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/08/13 15:24:08 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:196) finished in 0,004 s
17/08/13 15:24:08 INFO DAGScheduler: Job 18 finished: collect at utils.scala:196, took 0,024609 s
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:35673 in memory (size: 11.5 KB, free: 365.2 MB)
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1290
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:35673 in memory (size: 13.1 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:35673 in memory (size: 11.5 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1448
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:35673 in memory (size: 13.0 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1131
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:35673 in memory (size: 12.9 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:35673 in memory (size: 3.7 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:35673 in memory (size: 13.0 KB, free: 365.3 MB)
17/08/13 15:25:33 INFO ContextCleaner: Cleaned shuffle 6
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1034
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1033
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1032
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1031
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1030
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1029
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1028
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1027
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1026
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1025
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1024
17/08/13 15:25:33 INFO ContextCleaner: Cleaned accumulator 1023
17/08/13 15:25:33 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:35673 in memory (size: 16.9 KB, free: 365.3 MB)
17/08/13 15:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:27:22 INFO SparkSqlParser: Parsing command: SELECT * FROM df LIMIT 5
17/08/13 15:27:22 INFO SparkContext: Starting job: collect at utils.scala:196
17/08/13 15:27:22 INFO DAGScheduler: Got job 19 (collect at utils.scala:196) with 1 output partitions
17/08/13 15:27:22 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:196)
17/08/13 15:27:22 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:27:22 INFO DAGScheduler: Missing parents: List()
17/08/13 15:27:22 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[125] at collect at utils.scala:196), which has no missing parents
17/08/13 15:27:22 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 26.3 KB, free 364.5 MB)
17/08/13 15:27:22 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 11.5 KB, free 364.4 MB)
17/08/13 15:27:22 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:35673 (size: 11.5 KB, free: 365.3 MB)
17/08/13 15:27:22 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
17/08/13 15:27:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[125] at collect at utils.scala:196)
17/08/13 15:27:22 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/08/13 15:27:22 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 6565 bytes)
17/08/13 15:27:22 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
17/08/13 15:27:22 INFO BlockManager: Found block rdd_92_0 locally
17/08/13 15:27:22 WARN Executor: 1 block locks were not released by TID = 29:
[rdd_92_0]
17/08/13 15:27:22 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 2369 bytes result sent to driver
17/08/13 15:27:22 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 7 ms on localhost (executor driver) (1/1)
17/08/13 15:27:22 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/08/13 15:27:22 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:196) finished in 0,008 s
17/08/13 15:27:22 INFO DAGScheduler: Job 19 finished: collect at utils.scala:196, took 0,014409 s
17/08/13 15:34:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/08/13 15:34:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/08/13 15:34:07 INFO SparkContext: Starting job: take at NativeMethodAccessorImpl.java:0
17/08/13 15:34:07 INFO DAGScheduler: Got job 20 (take at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/08/13 15:34:07 INFO DAGScheduler: Final stage: ResultStage 30 (take at NativeMethodAccessorImpl.java:0)
17/08/13 15:34:07 INFO DAGScheduler: Parents of final stage: List()
17/08/13 15:34:07 INFO DAGScheduler: Missing parents: List()
17/08/13 15:34:07 INFO DAGScheduler: Submitting ResultStage 30 (WorkerRDD[129] at RDD at rdd.scala:16), which has no missing parents
17/08/13 15:34:07 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 30.6 KB, free 364.4 MB)
17/08/13 15:34:07 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 12.9 KB, free 364.4 MB)
17/08/13 15:34:07 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:35673 (size: 12.9 KB, free: 365.3 MB)
17/08/13 15:34:07 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/08/13 15:34:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (WorkerRDD[129] at RDD at rdd.scala:16)
17/08/13 15:34:07 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/08/13 15:34:07 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 6618 bytes)
17/08/13 15:34:07 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
17/08/13 15:34:07 INFO BlockManager: Found block rdd_92_0 locally
17/08/13 15:38:37 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 162600 ms exceeds timeout 120000 ms
17/08/13 15:38:37 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2812331f,BlockManagerId(driver, 127.0.0.1, 35673, None))] in 1 attempts
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:48)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:63)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(package.scala:190)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(package.scala:190)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
	... 14 more
17/08/13 15:38:37 ERROR TaskSchedulerImpl: Lost executor driver on localhost: Executor heartbeat timed out after 162600 ms
17/08/13 15:38:37 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply in 10 seconds
17/08/13 15:38:37 WARN BlockManager: Putting block rdd_129_0 failed due to an exception
17/08/13 15:38:37 WARN BlockManager: Block rdd_129_0 could not be removed as it was not found on disk or in memory
17/08/13 15:38:37 INFO SparkContext: Invoking stop() from shutdown hook
17/08/13 15:38:37 ERROR Executor: Exception in task 0.0 in stage 30.0 (TID 30)
java.lang.Exception: sparklyr worker rscript failure, check worker logs for details.
	at sparklyr.Rscript.init(rscript.scala:56)
	at sparklyr.WorkerRDD$$anon$2.run(rdd.scala:89)
17/08/13 15:38:37 WARN TaskSetManager: Lost task 0.0 in stage 30.0 (TID 30, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 162600 ms
17/08/13 15:38:37 ERROR TaskSetManager: Task 0 in stage 30.0 failed 1 times; aborting job
17/08/13 15:38:37 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/08/13 15:38:37 INFO TaskSchedulerImpl: Cancelling stage 30
17/08/13 15:38:37 INFO DAGScheduler: ResultStage 30 (take at NativeMethodAccessorImpl.java:0) failed in 270,126 s due to Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 30, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 162600 ms
Driver stacktrace:
17/08/13 15:38:37 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/08/13 15:38:37 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(true)
17/08/13 15:38:37 INFO DAGScheduler: Job 20 failed: take at NativeMethodAccessorImpl.java:0, took 270,139339 s
17/08/13 15:38:39 WARN SparkContext: Killing executors is only supported in coarse-grained mode
17/08/13 15:38:39 INFO DAGScheduler: Executor lost: driver (epoch 10)
17/08/13 15:38:39 INFO BlockManagerMasterEndpoint: Trying to remove executor driver from BlockManagerMaster.
17/08/13 15:38:39 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerRemoved(1502653119204,BlockManagerId(driver, 127.0.0.1, 35673, None))
17/08/13 15:38:39 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(driver, 127.0.0.1, 35673, None)
17/08/13 15:38:41 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2812331f,BlockManagerId(driver, 127.0.0.1, 35673, None))] in 2 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Could not find HeartbeatReceiver.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:154)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 13 more
17/08/13 15:38:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/08/13 15:38:41 INFO MemoryStore: MemoryStore cleared
17/08/13 15:38:41 INFO BlockManager: BlockManager stopped
17/08/13 15:38:41 INFO BlockManagerMaster: BlockManagerMaster stopped
17/08/13 15:38:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/08/13 15:38:44 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@1849926 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@d8534f1[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2]
17/08/13 15:38:44 WARN NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2812331f,BlockManagerId(driver, 127.0.0.1, 35673, None))] in 3 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 13 more
17/08/13 15:38:44 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2812331f,BlockManagerId(driver, 127.0.0.1, 35673, None))]
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:119)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:538)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:567)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:567)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	... 13 more
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:129)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:507)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 13 more
17/08/13 15:38:44 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 30 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
17/08/13 15:38:44 INFO SparkContext: Successfully stopped SparkContext
17/08/13 15:38:44 INFO ShutdownHookManager: Shutdown hook called
17/08/13 15:38:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-2f4ce049-6e85-4156-8edf-898b1280e793
